---
title: "shapley"
author: "Vignette Author"
date: '`r Sys.Date()`'
output:
  pdf_document: default
  html_document: default
vignette: |
  %\VignetteIndexEntry{shapley} %\VignetteEngine{knitr::rmarkdown} %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE,results='hide'}
library(ggplot2)
#library(shapleyr)
#load the packages that we need
devtools::load_all()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(collapse = T, comment = "#>")
```

## R Shapley

The Shapley value is a method that gives a solution to the following problem: A coalition of players play a game, for which they get a payout, but it is not clear how to distribute the payout fairly among the players. The Shapley value solves this problem by trying out different coalitions of players to decide how much each player changes the amount of the payout. 
What does this have to do with machine learning? In machine learning, the features (=players) work together to get the payout (=predicted value). The Shapley value tells us, how much each feature contributed to the prediction.
Properties:
  * Pareto-efficiency.
  * Symmetry.
  * Additivity.
  * Zero player.

# Shapley value

###example1: 
### regression task
```{r}
#   task = bh.task,      predict.methods = regr.lm
s1 <-shapley(3, task = bh.task, model = train(makeLearner("regr.lm"), bh.task))
# shapley Value
knitr::kable(getShapleyValues(s1))
```
###example2:
### classification task
```{r}
#  task = iris.task,      predict.methods = classif.lda
s2 <-shapley(3, task = iris.task, model = train(makeLearner("classif.lda"), iris.task))
# shapley Value
knitr::kable(getShapleyValues(s2))
```

###example3:
### multilabel task
```{r}
#  task = yeast.task,      predict.methods = multilabel.rFerns
s3 <-shapley(3, task = yeast.task, model = train(makeLearner("multilabel.rFerns"), yeast.task))
# shapley Value
knitr::kable(getShapleyValues(s3))
```

###example4:
### cluster task
```{r}
#  task = mtcars.task,      predict.methods = cluster.kmeans
s4 <-shapley(5, task = mtcars.task, model = train(makeLearner("cluster.kmeans"), mtcars.task))
# shapley Value
knitr::kable(getShapleyValues(s4))
```

###example5:
### calculate shapley value without sampling
```{r}
### Unsampled version created for calculating the exact shapley value.
### A lot to calculate, because every permutation needs to be calculated
s5 <-shapley.unsampled()

```

An example how to calculate the Shapley value of feature b:

Permutationen        Beitrag vor b     vor und mit b    Marginaler Beitrag
-------------       --------------     --------------   -------------------
        a,b,c       v({a}) = 12         v({a,b})=24              12 = 24-12
        a,c,b       v({a,c}) = 27       v({a,b,c}) = 36           9 = 36-27
        b,a,c       v({}) = 0           v({b}) = 6                6
        b,c,a       v({}) = 0           v({b}) = 6                6
        c,a,b       v({a,c}) = 27       v({a,b,c}) = 36           9
        c,b,a       v({c}) = 9          v({b,c}) = 15             6
-------------       --------------     --------------  --------------------
Result: Sh_b({a,b,c}, v) = 8
Same for Sh_a = 17, Sh_c = 11



# Including Plots

This method draws a plot for, the observed value and describes the influence of features we interested.

```{r}

#plot.shapley.singleValue(3, shap.values = NULL, task = bh.task,
 # model = train("regr.lm", bh.task))

```

This method draws a plot for, the observed value and describes the influence of multiple features we interested .
```{r}

#plot.shapley.multipleFeatures(1:2,features = c("crim","rad","tax","nox"))
```

```{r, echo = FALSE}
#knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```
# Converges
Tests that the shapley algorithm converges
parameters are : 
    row.nr Index for the observation of interest.
    iterations Amount of iterations.
    shapley.iterations Amount of the iterations within the shapley
    function.
return shapley value as a data.frame with col.names and their corresponding
effects.

```{r, echo = TRUE}
#test.convergence(row.nr = 1, iterations = 20, shapley.iterations = 1, model, task)
#plot the convergence
#test.convergence(1, iterations = 20, shapley.iterations = 1)
```


